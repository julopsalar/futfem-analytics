{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50b6b02c-3378-46f5-892c-e86856938e6e",
   "metadata": {},
   "source": [
    "This notebook shows how data from different Womens' Leagues are collected, using *Python* and *BeautyfulSoup*, and how this data will be loaded into a *Microsoft SQL Server* for later use in *Power BI*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9418b30-ee08-4228-a440-aae850b14287",
   "metadata": {},
   "source": [
    "# Imports and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae272251-2f43-44d8-9334-7648834036be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  league_id          league_name\n",
      "0       230               Liga-F\n",
      "1       189  Womens-Super-League\n",
      "2       193  Division-1-Feminine\n",
      "3       183    Frauen-Bundesliga\n",
      "4       208              Serie-A\n",
      "2022-12-11 10:23:33.628544\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import pause, datetime\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from xPoints import *\n",
    "\n",
    "\n",
    "leagues = [\n",
    "    ['230', 'Liga-F'],\n",
    "    ['189', 'Womens-Super-League'],\n",
    "    ['193', 'Division-1-Feminine'],\n",
    "    ['183', 'Frauen-Bundesliga'],\n",
    "    ['208', 'Serie-A']\n",
    "]\n",
    "\n",
    "league_ids = pd.DataFrame(leagues, columns=['league_id', 'league_name'])\n",
    "print(league_ids)\n",
    "\n",
    "keys = [\n",
    "    'stats',\n",
    "    'shooting',\n",
    "    'passing',\n",
    "    #'passing_types', NOT INTERESTING FOR ME...\n",
    "    'gca',\n",
    "    'defense',\n",
    "    'possession',\n",
    "    'playingtime',\n",
    "    'misc'\n",
    "]\n",
    "\n",
    "gk_keys = [\n",
    "    'keepers',\n",
    "    'keepersadv'\n",
    "]\n",
    "\n",
    "url_base = 'https://fbref.com/en/comps/%s/%s/%s'\n",
    "\n",
    "# Create Requesting session\n",
    "session = requests.Session()\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b683bc-041e-4600-b484-119696dcae0a",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec3a95ef-faf2-46a6-9ba2-f615fa31d94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tables(url):\n",
    "\n",
    "    res = session.get(url)\n",
    "    # Updating cookies to avoid fbref blocking\n",
    "    cookies = session.cookies.get_dict()\n",
    "    cookies['User-Agent'] = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:107.0) Gecko/20100101 Firefox/107.0'\n",
    "    session.headers.update(cookies)\n",
    "    \n",
    "    comm = re.compile(\"<!--|-->\")\n",
    "    soup = BeautifulSoup(comm.sub(\"\", res.text), 'lxml')\n",
    "    data = [pd.read_html(str(t), extract_links='body')[0] for t in soup.find_all('table')]\n",
    "    return data\n",
    "\n",
    "\n",
    "delete_colnames = [\n",
    "    'Performance', 'Playing Time', 'Penalty Kicks', 'Expected', 'Standard', 'A', \n",
    "    'SCA', 'GCA', 'Starts', 'Subs' #, 'Team Success', 'Team Success (xG)'\n",
    "]\n",
    "\n",
    "def parse_multilevel_dataframe(data):\n",
    "    colnames = []\n",
    "    for (l0, l1) in list(data):\n",
    "        if l0 in ['Per 90 Minutes']:\n",
    "            colnames.append(l1 + '_90')\n",
    "        else:\n",
    "            if (l0 in delete_colnames) | (re.match(r'Unnamed.*', l0) != None):\n",
    "                colnames.append(l1)\n",
    "            else:\n",
    "                colnames.append(l0 + '_' + l1)\n",
    "    \n",
    "    data = data.droplevel(0, axis=1)\n",
    "    data.columns = colnames\n",
    "    # Drop % columns and normalized by 90 minutes\n",
    "    data = data[data.columns.drop(list(data.filter(regex='(%)|(90)')))]\n",
    "    return data\n",
    "\n",
    "def parse_link(id_url):\n",
    "    link_regex = r'/en/([^/]+)/([^/]+)/.+'\n",
    "    m = re.match(link_regex, str(id_url))\n",
    "    if m:\n",
    "        return m.groups()[1]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def parse_id_columns(data):\n",
    "    for col in list(data):\n",
    "        try:\n",
    "            data[[col, col+'_id']] = pd.DataFrame(data[col].tolist(), index=data.index)\n",
    "            data[col+'_id'] = data[col+'_id'].apply(lambda x: parse_link(x))\n",
    "        except:\n",
    "            data[col] = data[col].squeeze().copy()\n",
    "            print('Error: ', col)\n",
    "    data = data.drop_duplicates(keep=False).reset_index(drop=True)\n",
    "    data.dropna(axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d36b08-6e9b-46dd-be5c-133b53a222c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Match Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31aaa8e6-e25e-4cdf-82ce-dec106d36a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing league  Liga-F  matches...\n",
      "\n",
      "Processing league  Womens-Super-League  matches...\n",
      "\n",
      "Processing league  Division-1-Feminine  matches...\n",
      "\n",
      "Processing league  Frauen-Bundesliga  matches...\n",
      "\n",
      "Processing league  Serie-A  matches...\n",
      "All matches proccessed\n"
     ]
    }
   ],
   "source": [
    "matches = []\n",
    "for idx, l in league_ids.iterrows(): \n",
    "    print('\\nProcessing league ', l[1], ' matches...')\n",
    "\n",
    "    url_scrape = url_base % (str(l[0]), 'schedule', l[1])\n",
    "    tables = get_tables(url_scrape)\n",
    "    m = tables[0]\n",
    "    m = parse_id_columns(m)\n",
    "    m['League_id'] = [l[0]] * m.shape[0]\n",
    "    \n",
    "    matches.append(m)\n",
    "    req_time = datetime.datetime.now()\n",
    "    # Timeout to avoid FBRef banning\n",
    "    pause.until(req_time + datetime.timedelta(0,3.5))\n",
    "    \n",
    "\n",
    "matches = pd.concat(matches)\n",
    "matches = matches[matches['Match Report'] == \"Match Report\"]\n",
    "matches.rename(columns={'xG':'xGHome', 'xG.1':'xGAway', 'Match Report_id':'Match_id'}, inplace=True)\n",
    "\n",
    "home_xp, away_xp = calculate_xpoints(matches=matches, num_simulations=50000, debug=False)\n",
    "matches.loc[:, 'xPHome'] = home_xp\n",
    "matches.loc[:, 'xPAway'] = away_xp\n",
    "\n",
    "matches[['ScoreHome','ScoreAway']] = matches['Score'].str.split('â€“',expand=True)\n",
    "matches.drop(columns=['Attendance', 'Venue', 'Referee', 'Match Report', 'Notes'], inplace=True)\n",
    "\n",
    "matches.to_csv('datasets/matches.csv', index=False)\n",
    "print('All matches proccessed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf1ca05-8cbb-47bd-a92f-e506689d8c6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Stats by Teams and Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61a72bc1-03f1-45ea-a1a6-c6376d460f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing league  Liga-F \n",
      "Scraping:  stats..  shooting..  passing..  gca..  defense..  possession..  playingtime..  misc..  \n",
      "_______\n",
      "\n",
      "Processing league  Womens-Super-League \n",
      "Scraping:  stats..  shooting..  passing..  gca..  defense..  possession..  playingtime..  misc..  \n",
      "_______\n",
      "\n",
      "Processing league  Division-1-Feminine \n",
      "Scraping:  stats..  shooting..  passing..  gca..  defense..  possession..  playingtime..  misc..  \n",
      "_______\n",
      "\n",
      "Processing league  Frauen-Bundesliga \n",
      "Scraping:  stats..  shooting..  passing..  gca..  defense..  possession..  playingtime..  misc..  \n",
      "_______\n",
      "\n",
      "Processing league  Serie-A \n",
      "Scraping:  stats..  shooting..  passing..  gca..  defense..  possession..  playingtime..  misc..  \n",
      "_______\n",
      "Data scrapped in  189.63  seconds\n"
     ]
    }
   ],
   "source": [
    "teams_leagues = []\n",
    "players_leagues = []\n",
    "\n",
    "start_time = time.time()\n",
    "for idx, l in league_ids.iterrows(): \n",
    "    print('\\nProcessing league ', l[1], '\\nScraping:', end='  ')\n",
    "    teams = []\n",
    "    players = []\n",
    "    for k in keys:\n",
    "        print(k, end='..  ')\n",
    "        url_scrape = url_base % (str(l[0]), k, l[1])\n",
    "        tables = get_tables(url_scrape)\n",
    "        req_time = datetime.datetime.now()\n",
    "\n",
    "        t, p = tables[0], tables[2]\n",
    "        t, p = parse_multilevel_dataframe(t), parse_multilevel_dataframe(p)\n",
    "        t, p = parse_id_columns(t), parse_id_columns(p)\n",
    "        t['League_id'] = [l[0]] * t.shape[0]\n",
    "        teams.append(t)\n",
    "        players.append(p)\n",
    "        # Timeout to avoid FBRef banning\n",
    "        pause.until(req_time + datetime.timedelta(0,3.5))\n",
    "\n",
    "    print('\\n_______')\n",
    "    # Drop NA and duplicated columns\n",
    "    all_pl = pd.concat(players, axis=1).dropna()\n",
    "    all_teams = pd.concat(teams, axis=1).dropna()\n",
    "    teams_leagues.append(all_teams.loc[:,~all_teams.columns.duplicated()])\n",
    "    players_leagues.append(all_pl.loc[:,~all_pl.columns.duplicated()])\n",
    "\n",
    "print('Data scrapped in ', round(time.time() - start_time, 2), ' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdd7bc9-0461-40a1-831c-261b33d8805a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77745f70-6014-4612-a120-e83f89b08c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1332, 78)\n"
     ]
    }
   ],
   "source": [
    "# Merge different leagues\n",
    "players_stats = pd.concat(players_leagues)\n",
    "\n",
    "players_stats = players_stats[players_stats.columns.drop(list(players_stats.filter(regex=r'(Short*)|(Medium*)|(Long*)|(SCA_*)|(GCA_*)')))]\n",
    "# Parse Minutes Played (1,000 -> 1000)\n",
    "players_stats['Min'] = players_stats['Min'].apply(lambda x: int(x.replace(',', '')))\n",
    "\n",
    "players_stats.rename(columns=lambda x: re.sub('\\sTypes','',x), inplace=True)\n",
    "players_stats.rename(columns=lambda x: re.sub('1/3','LastThird',x), inplace=True)\n",
    "# 0,1,2\n",
    "players_stats.rename(columns=lambda x: re.sub('\\+/\\-','Diff',x), inplace=True)\n",
    "players_stats.rename(columns=lambda x: re.sub('\\+','_plus_',x), inplace=True)\n",
    "players_stats.rename(columns=lambda x: re.sub('\\s+','',x), inplace=True)\n",
    "# Playtime and misc\n",
    "players_stats.rename(columns=lambda x: re.sub('/','_by_',x), inplace=True)\n",
    "players_stats.rename(columns=lambda x: re.sub('Total_','Passes_',x), inplace=True)\n",
    "\n",
    "players_stats.rename(columns=lambda x: re.sub('TeamSuccess(\\s\\(xG\\))*','TS',x), inplace=True)\n",
    "\n",
    "players_stats.drop(columns=['Rk', 'Matches', 'Matches_id', 'npxG_plus_xAG', 'G-PK', \\\n",
    "                            'Cmp', 'Mn_by_MP', 'Mn_by_Start', 'Compl', 'Mn_by_Sub', \\\n",
    "                            'G-PK', 'G_by_Sh', 'G_by_SoT', 'PKwon', 'xA', 'A-xAG', 'Prog', 'Tackles_TklW', \\\n",
    "                            'VsDribbles_Tkl', 'VsDribbles_Att', 'VsDribbles_Past', 'Tkl_plus_Int', \\\n",
    "                            'Dribbles_Mis', 'Dribbles_Dis',] ,\\\n",
    "                   inplace=True)\n",
    "players_stats.rename(columns={'Tackles_Tkl':'Tkl', 'Blocks_Blocks':'Blocks', 'Touches_Touches':'Touches'}, inplace=True)\n",
    "\n",
    "players_stats.iloc[:,5:] = players_stats.iloc[:,5:].fillna(0)\n",
    "print(players_stats.shape)\n",
    "\n",
    "players_stats.to_csv('datasets/all_players.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4164810-3d2d-4267-85eb-eebeb0d983a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 88)\n"
     ]
    }
   ],
   "source": [
    "# Merge different leagues\n",
    "teams_stats = pd.concat(teams_leagues)\n",
    "teams_stats.iloc[:,1:] = teams_stats.iloc[:,1:].fillna(0)\n",
    "\n",
    "teams_stats = teams_stats[teams_stats.columns.drop(list(teams_stats.filter(regex=r'(Short*)|(Medium*)|(Long*)')))]\n",
    "teams_stats.rename(columns=lambda x: re.sub('\\sTypes','',x), inplace=True)\n",
    "teams_stats.rename(columns=lambda x: re.sub('1/3','LastThird',x), inplace=True)\n",
    "# 0,1,2\n",
    "teams_stats.rename(columns=lambda x: re.sub('\\+/\\-','Diff',x), inplace=True)\n",
    "teams_stats.rename(columns=lambda x: re.sub('\\+','_plus_',x), inplace=True)\n",
    "teams_stats.rename(columns=lambda x: re.sub('\\s+','',x), inplace=True)\n",
    "# Playtime and misc\n",
    "teams_stats.rename(columns=lambda x: re.sub('/','_by_',x), inplace=True)\n",
    "teams_stats.rename(columns=lambda x: re.sub('TeamSuccess(\\s\\(xG\\))*','TS',x), inplace=True)\n",
    "teams_stats.rename(columns=lambda x: re.sub('Total_','Passes_',x), inplace=True)\n",
    "\n",
    "teams_stats.drop(columns=['npxG_plus_xAG', 'G-PK', \\\n",
    "                            'Cmp', 'Mn_by_MP', 'Mn_by_Start', 'Compl', 'Mn_by_Sub', \\\n",
    "                            'G-PK', 'G_by_Sh', 'G_by_SoT', 'PKwon', 'xA', 'A-xAG', 'Prog', 'Tackles_TklW', \\\n",
    "                            'VsDribbles_Tkl', 'VsDribbles_Att', 'VsDribbles_Past', 'Tkl_plus_Int', \\\n",
    "                            'Dribbles_Mis', 'Dribbles_Dis',] ,\\\n",
    "                   inplace=True)\n",
    "teams_stats.rename(columns={'Tackles_Tkl':'Tkl', 'Blocks_Blocks':'Blocks', 'Touches_Touches':'Touches'}, inplace=True)\n",
    "\n",
    "print(teams_stats.shape)\n",
    "teams_stats.to_csv('datasets/all_teams.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bf2696-a529-4f09-895c-39863fbc6972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cee7c0e-3ab1-4649-ae6b-fa3bf83f82f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Goalkeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d65bf666-af5e-4a51-a140-fb3007e26609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing league  Liga-F \n",
      "Scraping:  keepers,    keepersadv,    \n",
      "_______\n",
      "\n",
      "Processing league  Womens-Super-League \n",
      "Scraping:  keepers,    keepersadv,    \n",
      "_______\n",
      "\n",
      "Processing league  Division-1-Feminine \n",
      "Scraping:  keepers,    keepersadv,    \n",
      "_______\n",
      "\n",
      "Processing league  Frauen-Bundesliga \n",
      "Scraping:  keepers,    keepersadv,    \n",
      "_______\n",
      "\n",
      "Processing league  Serie-A \n",
      "Scraping:  keepers,    keepersadv,    \n",
      "_______\n",
      "Data scrapped in  41.47  seconds\n"
     ]
    }
   ],
   "source": [
    "gk_teams_leagues = []\n",
    "gk_players_leagues = []\n",
    "\n",
    "start_time = time.time()\n",
    "for idx, l in league_ids.iterrows(): \n",
    "    print('\\nProcessing league ', l[1], '\\nScraping:', end='  ')\n",
    "    teams = []\n",
    "    players = []\n",
    "    for k in gk_keys:\n",
    "        print(k, end=',    ')\n",
    "        url_scrape = url_base % (str(l[0]), k, l[1])\n",
    "        tables = get_tables(url_scrape)\n",
    "        req_time = datetime.datetime.now()\n",
    "        t, p = tables[0], tables[2]\n",
    "        t, p = parse_multilevel_dataframe(t), parse_multilevel_dataframe(p)\n",
    "        t, p = parse_id_columns(t), parse_id_columns(p)\n",
    "        t['League_id'] = [l[0]] * t.shape[0]\n",
    "        teams.append(t)\n",
    "        p = p[p['Rk'] != 'Rk']\n",
    "        players.append(p)\n",
    "        # Timeout to avoid FBRef banning\n",
    "        pause.until(req_time + datetime.timedelta(0,3.5))\n",
    "    \n",
    "    all_teams = pd.concat(teams, axis=1)\n",
    "    all_pl = pd.concat(players, axis=1)\n",
    "    gk_teams_leagues.append(all_teams.loc[:,~all_teams.columns.duplicated()])\n",
    "    gk_players_leagues.append(all_pl.loc[:,~all_pl.columns.duplicated()])\n",
    "    print('\\n_______')\n",
    "\n",
    "print('Data scrapped in ', round(time.time() - start_time, 2), ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeef3d6a-cd92-4b41-a210-fde8041c3870",
   "metadata": {},
   "outputs": [],
   "source": [
    "gk_teams = pd.concat(gk_teams_leagues)\n",
    "gk_players = pd.concat(gk_players_leagues) \n",
    "\n",
    "# Cleaning null rows, columns and colnames\n",
    "gk_players.drop(columns=['Rk', 'Nation', 'Age', 'Born', 'Matches'], inplace=True)\n",
    "\n",
    "# Parse Minutes Played (1,000 -> 1000)\n",
    "gk_players['Min'] = gk_players['Min'].apply(lambda x: int(x.replace(',', '')))\n",
    "gk_teams['Min'] = gk_teams['Min'].apply(lambda x: int(x.replace(',', '')))\n",
    "\n",
    "gk_players.dropna(axis=1, inplace=True)\n",
    "gk_players.dropna(axis=0, inplace=True)\n",
    "gk_players.rename(columns={'CS':'Clean Sheets'}, inplace=True)\n",
    "gk_players.rename(columns=lambda x: re.sub('\\s+','',x), inplace=True)\n",
    "\n",
    "gk_teams.rename(columns={'CS':'Clean Sheets'}, inplace=True)\n",
    "gk_teams.rename(columns=lambda x: re.sub('\\s+','',x), inplace=True)\n",
    "\n",
    "gk_teams.to_csv('datasets/gk_teams.csv', index=False)\n",
    "gk_players.to_csv('datasets/gk_players.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce840f9d-fb3f-436b-9f3e-4a0c63cc8fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-11 10:28:32.515576\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
